Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
2000,1.3665425,0.0002994087,-13.315487,28.764800805585562,193.55555555555554,28.764802142977715
4000,1.0427544,0.00029819927,-8.608824,11.027613650044628,29.10810810810811,11.19354063231651
6000,1.1393855,0.00029700526,-11.748458,34.129583647008985,109.94444444444444,34.13999129169517
8000,1.4034423,0.0002958003,-2.6008992,31.930108312640876,58.72727272727273,31.92482111128894
10000,1.4467285,0.00029460675,0.64052284,27.948314354518274,65.06666666666666,27.840341774125893
12000,1.2600842,0.00029340677,-0.59462297,11.297450123535356,39.36734693877551,11.363109212444753
14000,1.0772747,0.00029220042,1.5811535,5.771029369226928,20.956043956043956,5.770595482090017
16000,0.56859314,0.00029101138,-0.87476355,1.4750078419418298,13.16304347826087,1.4480015347080846
18000,0.76476085,0.0002898077,-48.226376,95.36052442545241,241.27272727272728,104.99985293671489
20000,0.8536752,0.00028861532,10.961531,45.22989510056734,85.78947368421052,42.91675943657756
22000,1.3755271,0.0002874102,-2.6198213,48.759354273173294,79.28571428571429,48.75935300546033
