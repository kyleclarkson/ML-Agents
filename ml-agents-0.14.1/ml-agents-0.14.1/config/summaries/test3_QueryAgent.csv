Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length
1000,1.8200307,0.00029992967,-13.718336,-773955.9559159875,985.0
2000,1.4137511,0.00029977967,-25.69387,-1584215.2166748047,984.0
3000,1.2597749,0.00029962964,-45.92813,-2676553.675048828,984.0
4000,1.3734696,0.00029947967,-28.157177,-2759264.566772461,984.0
5000,1.3626608,0.00029932964,-58.31428,-4216856.502441406,984.0
6000,1.234621,0.00029917952,-58.765705,-5074429.1875,985.0
7000,0.95337415,0.00029902952,-65.952415,-5857326.811767578,984.0
8000,0.40895668,0.00029887952,-67.427,-4209972.75,984.0
9000,0.017327983,0.0002987295,-107.59306,-6210215.1162109375,984.0
10000,0.0033524388,0.0002985795,-142.54993,-8211257.495605469,984.0
11000,0.45874316,0.00029842937,-238.48727,-8169228.371582031,985.0
12000,0.5456748,0.00029827937,-274.17468,-8089023.687988281,984.0
13000,0.64607954,0.00029812937,-331.4249,-10089642.58203125,984.0
14000,0.23937395,0.00029797934,-389.4093,-12091061.639160156,984.0
15000,0.06551693,0.00029782933,-451.4281,-14093280.727539062,984.0
