Steps,Policy/Entropy,Policy/Learning Rate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward
2000,0.38175416,0.00029969972,-19336.596666753292,999.5,3.4779103,-18689.193359375
3000,0.00038570512,0.00029879945,-19988.0,999.0,-11.541099,-19984.0
4000,3.325379e-06,0.00029819942,-19992.0,999.0,-27.233809,-19988.0
5000,2.3347255e-08,0.00029759944,-19996.0,999.0,-42.109,-19992.0
6000,1.7040185e-10,0.00029699944,-20000.0,1000.0,-56.828136,-19996.0
7000,1.2470459e-12,0.00029639882,-19984.0,999.0,-71.500755,-20000.0
8000,8.895135e-15,0.0002957988,-19988.0,999.0,-86.06941,-19984.0
9000,6.2055255e-17,0.00029519878,-19992.0,999.0,-100.64264,-19988.0
10000,4.2611007e-19,0.00029459878,-19996.0,999.0,-115.22173,-19992.0
11000,2.8977e-21,0.0002939988,-20000.0,1000.0,-129.8018,-19996.0
12000,1.9638995e-23,0.00029339825,-19984.0,999.0,-144.3777,-20000.0
13000,1.3410675e-25,0.0002927982,-19988.0,999.0,-158.9276,-19984.0
14000,6.2007877e-10,0.00029219827,-19992.0,999.0,-173.44485,-19988.0
15000,1.03072904e-10,0.00029159817,-19996.0,999.0,-782.42267,-19992.0
16000,1.7041205e-11,0.0002909982,-20000.0,1000.0,-840.4112,-19996.0
17000,2.8039958e-12,0.00029039758,-19984.0,999.0,-898.42944,-20000.0
18000,4.601322e-13,0.0002897976,-19988.0,999.0,-956.4481,-19984.0
