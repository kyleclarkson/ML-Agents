Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
2000,1.0009193,0.00029994713,-77.38784,-762.7493777526543,1495.0,-762.7494220733643
4000,0.66686743,0.00029982647,-130.13516,-549.1970683727413,1494.0,-549.1970672607422
6000,0.9555405,0.00029970668,-82.37866,-220.52867435186636,1494.0,-175.62248706817627
8000,0.9987331,0.00029958715,-106.99545,-185.10176287137438,1494.0,-225.26831197738647
10000,0.6491721,0.00029946642,-71.700455,-75.91107609285973,1494.0,-75.91107416152954
12000,0.80853397,0.00029934666,-76.34486,-444.6615370907821,1494.0,-688.6486663818359
14000,0.3553703,0.00029922722,-100.12246,-621.1877810615115,1494.0,-410.93107306957245
16000,1.399218,0.0002991064,-53.019447,-38.526792803546414,1494.0,-38.52678918838501
18000,1.251708,0.00029898665,-52.410744,-96.53364167205291,1494.5,-19.492793798446655
20000,0.9368752,0.0002988671,-93.26835,-32.19826008507516,1494.0,-102.88636973500252
22000,0.9403065,0.00029874637,-91.070206,-80.20165109925438,1494.0,-80.20165085792542
