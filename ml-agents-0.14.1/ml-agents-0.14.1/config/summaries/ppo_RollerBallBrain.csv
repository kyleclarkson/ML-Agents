Steps,Policy/Entropy,Policy/Learning Rate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss
10000,1.4125742,0.00029699228,0.24622030237580994,20.632829373650107,0.23302686,0.24675324675324675,0.037845742,0.24477364
20000,1.4052731,0.00029100265,0.7068527918781726,11.663705583756345,0.6672306,0.7068527918781726,0.046209797,0.23825997
30000,1.4088635,0.0002850043,0.930870083432658,10.917759237187127,0.8898617,0.929678188319428,0.017522205,0.23814638
40000,1.3955898,0.0002789925,0.978912319644839,10.102108768035515,0.93371147,0.978912319644839,0.006880486,0.24337965
